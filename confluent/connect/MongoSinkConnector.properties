# Copy this file and change the format to a json file and then run curl
# to add it in the kafka connect server
# Note install confluent-hub install mongodb/kafka-connect-mongodb:1.5.0 on confluent/connect pod
# To not having issue with Null pointer exception and ChangeStreamHandler class not found error
# Important Docs: https://www.mongodb.com/docs/kafka-connector/v1.5/sink-connector/fundamentals/post-processors/#std-label-sink-post-processors-document-id-adder

# Example:
# { "_id": "UUID" } : { "name": "Robert", "age": "Pieter" }

# Connector globally unique name
name=mongodb-sink-<TOPIC NAME>

########## Kafka configuration ##########
remote.bootstrap.servers=kafka1:9092, kafka2:9092
confluent.topic.security.protocol=PLAINTEXT
# The topic Kafka connect will use to store offsets. Mandatory if you want to have consistent consumer group
offset.storage.topic=<Topic to store offset for example connect-offsets>
topics=sourceA,sourceB
# Name of the class for this connector
connector.class=com.mongodb.kafka.connect.MongoSinkConnector
# Key converter class used to convert between Kafka connect format and the serialized form that is written to Kafka
key.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
# Value converter class used to convert between Kafka connect format and the serialized form that is written to Kafka
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=false
#########################################

########## MongoDB Connection Configuration Properties ##########
# The MongoDB connection URI string to connect to your MongoDB instance or cluster. default: mongodb://localhost:27017
connection.uri=mongodb://mongo1:27017,mongo2:27017,mongo3:27017, mongodb://<username>:<password>@<hostname>:<port>/?authSource=<authenticationDb>&authMechanism=SCRAM-SHA-256
auto.create=true
database=<mongo-db-name>
collection=<mongo-collection>
#################################################################


########## Connector Message Processing Properties ##########
max.batch.size=0 # to improve performance raise it up!
# Need to be true if the order of the save is important to you. If not it improves performance
bulk.write.ordered=true
# Number of batches of records the sink connector processes in order to trigger the rate limiting timeout. A value of 0 means no rate limiting.
rate.limiting.every.n=0
# How long (in milliseconds) to wait before the sink connector should resume processing after reaching the rate limiting threshold.
rate.limiting.timeout=0
# The maximum number of tasks to create for this connector. Multiple Tasks May Process Messages Out of Order if the topic has multiple partitions
tasks.max=1

########## Connector Error Handling Properties ##########
# Whether to continue processing messages if the connector encounters an error
errors.tolerance=all
# Name of topic to use as the dead letter queue
errors.deadletterqueue.topic.name=<name of topic to use as dead letter queue>
# should include the invalid message when logging an error
errors.log.include.messages=true
# Whether the connector should include context headers when it writes messages to the dead letter queue
errors.deadletterqueue.context.headers.enable=true
# Prevent invalid resume token error caused bys infrequently updated namespace
heartbeat.interval.ms=10000
#########################################################

########## Sink Connector Post-processor Properties ##########
# specify how the MongoDB Kafka sink connector should transform Kafka data before inserting it into MongoDB

# A list of field name mappings for key and value fields. Define the mappings in an inline JSON array
#field.renamer.mapping=[ { "oldName":"key.fieldA", "newName":"field1" }, { "oldName":"value.xyz", "newName":"abc" } ]
#field.renamer.regex=[]
# Inserts an _id field determined by the configured strategy. The default strategy is BsonOidStrategy
post.processor.chain=com.mongodb.kafka.connect.sink.processor.DocumentIdAdder
document.id.strategy=com.mongodb.kafka.connect.sink.processor.id.strategy.ProvidedInKeyStrategy
document.id.strategy.overwrite.existing=true
##############################################################

# https://www.mongodb.com/docs/kafka-connector/current/sink-connector/fundamentals/write-strategies/
########## Sink Connector Write Model Strategies ##########
# specify how the MongoDB Kafka sink connector writes data into MongoDB.

# Replaces at most one document in MongoDB that matches a sink record by the _id field. If no documents match, insert the sink record as a new document.
writemodel.strategy=com.mongodb.kafka.connect.sink.writemodel.strategy.ReplaceOneDefaultStrategy
delete.on.null.values=false
############################################################